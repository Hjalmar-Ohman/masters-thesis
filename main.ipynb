{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Skola\\Master's Thesis\\masters-thesis\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import faiss\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "import openai\n",
    "from transformers import CLIPProcessor, CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Skola\\Master's Thesis\\masters-thesis\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Hjalmar Ã–hman\\.cache\\huggingface\\hub\\models--openai--clip-vit-base-patch32. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_id = \"openai/clip-vit-base-patch32\"  # can be changed to another CLIP model\n",
    "clip_model = CLIPModel.from_pretrained(model_id).to(device)\n",
    "clip_processor = CLIPProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Create a cache dictionary in memory\n",
    "response_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_texts(texts, processor, model):\n",
    "    \"\"\"\n",
    "    Given a list of text strings, return their CLIP embeddings as a NumPy array.\n",
    "    \"\"\"\n",
    "    inputs = processor(\n",
    "        text=texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        text_embeddings = model.get_text_features(**inputs)\n",
    "    \n",
    "    # Normalize embeddings\n",
    "    text_embeddings = text_embeddings / text_embeddings.norm(dim=-1, keepdim=True)\n",
    "    return text_embeddings.cpu().numpy()\n",
    "\n",
    "def embed_images(images, processor, model):\n",
    "    \"\"\"\n",
    "    Given a list of PIL images, return their CLIP embeddings as a NumPy array.\n",
    "    \"\"\"\n",
    "    inputs = processor(\n",
    "        images=images,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_embeddings = model.get_image_features(**inputs)\n",
    "        \n",
    "    # Normalize embeddings\n",
    "    image_embeddings = image_embeddings / image_embeddings.norm(dim=-1, keepdim=True)\n",
    "    return image_embeddings.cpu().numpy()\n",
    "\n",
    "def get_faiss_index(dimension):\n",
    "    \"\"\"\n",
    "    Create and return a flat Faiss index of the specified dimension.\n",
    "    \"\"\"\n",
    "    index = faiss.IndexFlatIP(dimension)  # Using Inner Product (cosine similarity) \n",
    "    return index\n",
    "\n",
    "def add_to_index(index, embeddings):\n",
    "    \"\"\"\n",
    "    Add embeddings to a Faiss index.\n",
    "    \"\"\"\n",
    "    index.add(embeddings)\n",
    "\n",
    "def search_index(index, query_embedding, top_k=5):\n",
    "    \"\"\"\n",
    "    Search the Faiss index for the top_k nearest neighbors to query_embedding.\n",
    "    Returns (distances, indices).\n",
    "    \"\"\"\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    return distances, indices\n",
    "\n",
    "def retrieve_context(indices, metadata):\n",
    "    \"\"\"\n",
    "    Given a list of indices from Faiss, return the corresponding metadata (text snippets, image descriptions, etc.).\n",
    "    \"\"\"\n",
    "    retrieved = []\n",
    "    for idx in indices[0]:\n",
    "        retrieved.append(metadata[idx])\n",
    "    return retrieved\n",
    "\n",
    "def call_gpt_4(prompt):\n",
    "    \"\"\"\n",
    "    Calls GPT-4 with a prompt and returns the response.\n",
    "    Caching is used so repeated prompts are not re-sent to the API.\n",
    "    \"\"\"\n",
    "    if prompt in response_cache:\n",
    "        return response_cache[prompt]\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=200,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    answer = response['choices'][0]['message']['content']\n",
    "    \n",
    "    # Store in cache\n",
    "    response_cache[prompt] = answer\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "PDFInfoNotInstalledError",
     "evalue": "Unable to get page count. Is poppler installed and in PATH?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Skola\\Master's Thesis\\masters-thesis\\venv\\Lib\\site-packages\\pdf2image\\pdf2image.py:581\u001b[0m, in \u001b[0;36mpdfinfo_from_path\u001b[1;34m(pdf_path, userpw, ownerpw, poppler_path, rawdates, timeout, first_page, last_page)\u001b[0m\n\u001b[0;32m    580\u001b[0m     env[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLD_LIBRARY_PATH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m poppler_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m env\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLD_LIBRARY_PATH\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 581\u001b[0m proc \u001b[38;5;241m=\u001b[39m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1540\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPDFInfoNotInstalledError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m\n\u001b[0;32m     15\u001b[0m         text_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     16\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: page_text\u001b[38;5;241m.\u001b[39mstrip(),\n\u001b[0;32m     17\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage_number\u001b[39m\u001b[38;5;124m\"\u001b[39m: page_i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     18\u001b[0m         })\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Extract images\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# pdf2image.convert_from_path converts each PDF page into a PIL image\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m pages_as_images \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPDF_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoppler_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m..\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mpoppler-25.01.0\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mbin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# You can adjust the dpi\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, pil_img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pages_as_images):\n\u001b[0;32m     24\u001b[0m     image_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m: pil_img,\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage_number\u001b[39m\u001b[38;5;124m\"\u001b[39m: i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     27\u001b[0m     })\n",
      "File \u001b[1;32mc:\\Skola\\Master's Thesis\\masters-thesis\\venv\\Lib\\site-packages\\pdf2image\\pdf2image.py:127\u001b[0m, in \u001b[0;36mconvert_from_path\u001b[1;34m(pdf_path, dpi, output_folder, first_page, last_page, fmt, jpegopt, thread_count, userpw, ownerpw, use_cropbox, strict, transparent, single_file, output_file, poppler_path, grayscale, size, paths_only, use_pdftocairo, timeout, hide_annotations)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(poppler_path, PurePath):\n\u001b[0;32m    125\u001b[0m     poppler_path \u001b[38;5;241m=\u001b[39m poppler_path\u001b[38;5;241m.\u001b[39mas_posix()\n\u001b[1;32m--> 127\u001b[0m page_count \u001b[38;5;241m=\u001b[39m \u001b[43mpdfinfo_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserpw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mownerpw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoppler_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoppler_path\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# We start by getting the output format, the buffer processing function and if we need pdftocairo\u001b[39;00m\n\u001b[0;32m    132\u001b[0m parsed_fmt, final_extension, parse_buffer_func, use_pdfcairo_format \u001b[38;5;241m=\u001b[39m _parse_format(\n\u001b[0;32m    133\u001b[0m     fmt, grayscale\n\u001b[0;32m    134\u001b[0m )\n",
      "File \u001b[1;32mc:\\Skola\\Master's Thesis\\masters-thesis\\venv\\Lib\\site-packages\\pdf2image\\pdf2image.py:607\u001b[0m, in \u001b[0;36mpdfinfo_from_path\u001b[1;34m(pdf_path, userpw, ownerpw, poppler_path, rawdates, timeout, first_page, last_page)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m d\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PDFInfoNotInstalledError(\n\u001b[0;32m    608\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to get page count. Is poppler installed and in PATH?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    609\u001b[0m     )\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PDFPageCountError(\n\u001b[0;32m    612\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to get page count.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m     )\n",
      "\u001b[1;31mPDFInfoNotInstalledError\u001b[0m: Unable to get page count. Is poppler installed and in PATH?"
     ]
    }
   ],
   "source": [
    "PDF_FILE = \"knowledge/subset_monetary_policy_report.pdf\"\n",
    "\n",
    "text_data = []\n",
    "image_data = []\n",
    "\n",
    "# Extract text\n",
    "reader = PdfReader(PDF_FILE)\n",
    "num_pages = len(reader.pages)\n",
    "\n",
    "for page_i in range(num_pages):\n",
    "    page = reader.pages[page_i]\n",
    "    page_text = page.extract_text()\n",
    "    \n",
    "    # You might want to chunk the text if it's very long. Here we store the entire page text as one chunk.\n",
    "    if page_text and page_text.strip():\n",
    "        text_data.append({\n",
    "            \"text\": page_text.strip(),\n",
    "            \"page_number\": page_i + 1\n",
    "        })\n",
    "\n",
    "# Extract images\n",
    "# pdf2image.convert_from_path converts each PDF page into a PIL image\n",
    "pages_as_images = convert_from_path(PDF_FILE, dpi=200, poppler_path=r'C:\\Program Files\\poppler-0.68.0\\bin')  # You can adjust the dpi\n",
    "for i, pil_img in enumerate(pages_as_images):\n",
    "    image_data.append({\n",
    "        \"image\": pil_img,\n",
    "        \"page_number\": i + 1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metadata = []\n",
    "all_embeddings = []\n",
    "\n",
    "# 5A. Embed all text chunks\n",
    "texts_list = [td[\"text\"] for td in text_data]\n",
    "if len(texts_list) > 0:\n",
    "    text_embeddings = embed_texts(texts_list, clip_processor, clip_model)\n",
    "    for i, emb in enumerate(text_embeddings):\n",
    "        all_metadata.append({\n",
    "            \"type\": \"text\",\n",
    "            \"content\": text_data[i][\"text\"],\n",
    "            \"page_number\": text_data[i][\"page_number\"]\n",
    "        })\n",
    "        all_embeddings.append(emb)\n",
    "\n",
    "# 5B. Embed all images\n",
    "pil_images_list = [id_[\"image\"] for id_ in image_data]\n",
    "if len(pil_images_list) > 0:\n",
    "    image_embeddings = embed_images(pil_images_list, clip_processor, clip_model)\n",
    "    for i, emb in enumerate(image_embeddings):\n",
    "        all_metadata.append({\n",
    "            \"type\": \"image\",\n",
    "            \"content\": f\"Image from page {image_data[i]['page_number']}\",  # or store the actual PIL object if needed\n",
    "            \"page_number\": image_data[i][\"page_number\"]\n",
    "        })\n",
    "        all_embeddings.append(emb)\n",
    "\n",
    "# Convert to NumPy array\n",
    "all_embeddings = np.array(all_embeddings).astype('float32')\n",
    "embedding_dimension = all_embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = get_faiss_index(embedding_dimension)\n",
    "add_to_index(index, all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query(user_query, top_k=3):\n",
    "    \"\"\"\n",
    "    1. Embed the user query (assuming it's text).\n",
    "    2. Retrieve top_k similar items from the PDF (text or image).\n",
    "    3. Create a prompt for GPT-4 with the retrieved context.\n",
    "    4. Return GPT-4's answer.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Embed user query as text\n",
    "    query_emb = embed_texts([user_query], clip_processor, clip_model)  # shape: (1, D)\n",
    "    \n",
    "    # Step 2: Retrieve from Faiss\n",
    "    distances, indices = search_index(index, query_emb, top_k=top_k)\n",
    "    retrieved_items = retrieve_context(indices, all_metadata)\n",
    "    \n",
    "    # Build a context string. You may want more sophisticated formatting.\n",
    "    context_str_list = []\n",
    "    for item in retrieved_items:\n",
    "        context_str_list.append(\n",
    "            f\"({item['type']}, page {item['page_number']}): {item['content'][:500]}...\"  # truncate if needed\n",
    "        )\n",
    "    context_str = \"\\n\".join(context_str_list)\n",
    "    \n",
    "    # Step 3: Create a prompt for GPT-4\n",
    "    prompt = f\"\"\"\n",
    "The user asked: \"{user_query}\"\n",
    "\n",
    "I have the following context from the PDF:\n",
    "{context_str}\n",
    "\n",
    "Based on the context above (and only this context if possible), answer the query:\n",
    "\"\"\"\n",
    "    \n",
    "    # Step 4: Call GPT-4\n",
    "    answer = call_gpt_4(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query_1 = \"Give me a summary of the content in the PDF.\"\n",
    "response_1 = answer_query(user_query_1, top_k=3)\n",
    "print(\"Q:\", user_query_1)\n",
    "print(\"A:\", response_1)\n",
    "\n",
    "# Try the same query again and see if caching returns the same answer instantly.\n",
    "response_2 = answer_query(user_query_1, top_k=3)\n",
    "print(\"Q:\", user_query_1, \"(second time)\")\n",
    "print(\"A:\", response_2)\n",
    "\n",
    "# Another example query\n",
    "user_query_2 = \"Describe the images found on page 2.\"\n",
    "response_3 = answer_query(user_query_2, top_k=3)\n",
    "print(\"\\nQ:\", user_query_2)\n",
    "print(\"A:\", response_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
