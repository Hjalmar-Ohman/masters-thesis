{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. INSTALL / IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Skola\\Master's Thesis\\masters-thesis\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\" # TODO: This can introduce misscalculations. Opt for just CPU or GPU.\n",
    "\n",
    "import io\n",
    "import base64\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "import torch\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "from openai import OpenAI\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# In your notebook (example):\n",
    "from common_utils import embed_texts, embed_images, encode_image_to_base64, search_index, retrieve_context, call_gpt_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. CONFIGURE OPENAI & OTHER SETUPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\")  # Make sure your OpenAI key is set\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_id = \"openai/clip-vit-base-patch32\"\n",
    "clip_model = CLIPModel.from_pretrained(model_id).to(device)\n",
    "clip_processor = CLIPProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Create a cache dictionary in memory\n",
    "# response_cache = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. PROCESS THE PDF (TEXT + IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_FILE = \"knowledge/subset_monetary_policy_report.pdf\"\n",
    "\n",
    "text_data = []\n",
    "image_data = []\n",
    "\n",
    "# Extract text\n",
    "reader = PdfReader(PDF_FILE)\n",
    "num_pages = len(reader.pages)\n",
    "\n",
    "for page_i in range(num_pages):\n",
    "    page = reader.pages[page_i]\n",
    "    page_text = page.extract_text()\n",
    "    \n",
    "    if page_text and page_text.strip():\n",
    "        text_data.append({\n",
    "            \"text\": page_text.strip(),\n",
    "            \"page_number\": page_i + 1\n",
    "        })\n",
    "\n",
    "# Extract images\n",
    "pages_as_images = convert_from_path(PDF_FILE, dpi=200, poppler_path=r'poppler-24.08.0\\Library\\bin') \n",
    "for i, pil_img in enumerate(pages_as_images):\n",
    "    image_data.append({\n",
    "        \"image\": pil_img,\n",
    "        \"page_number\": i + 1\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. CREATE EMBEDDINGS FOR TEXT AND IMAGE CHUNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metadata = []\n",
    "all_embeddings = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5A. Embed all text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_list = [td[\"text\"] for td in text_data]\n",
    "if len(texts_list) > 0:\n",
    "    text_embeddings = embed_texts(texts_list, clip_processor, clip_model)\n",
    "    for i, emb in enumerate(text_embeddings):\n",
    "        all_metadata.append({\n",
    "            \"type\": \"text\",\n",
    "            \"content\": text_data[i][\"text\"],\n",
    "            \"page_number\": text_data[i][\"page_number\"]\n",
    "        })\n",
    "        all_embeddings.append(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B. Embed all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_images_list = [id_[\"image\"] for id_ in image_data]\n",
    "if len(pil_images_list) > 0:\n",
    "    image_embeddings = embed_images(pil_images_list, clip_processor, clip_model)\n",
    "    for i, emb in enumerate(image_embeddings):\n",
    "        \n",
    "        # Convert PIL image to base64 once (so we can send it to GPT-4 with Vision)\n",
    "        base64_str = encode_image_to_base64(image_data[i][\"image\"])\n",
    "        \n",
    "        all_metadata.append({\n",
    "            \"type\": \"image\",\n",
    "            # Store the base64 data directly as \"content\"\n",
    "            \"content\": base64_str,\n",
    "            \"page_number\": image_data[i][\"page_number\"]\n",
    "        })\n",
    "        all_embeddings.append(emb)\n",
    "\n",
    "# Convert to NumPy array\n",
    "all_embeddings = np.array(all_embeddings).astype('float32')\n",
    "embedding_dimension = all_embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. BUILD & POPULATE FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and return a flat Faiss index of the specified dimension.\n",
    "index = faiss.IndexFlatIP(embedding_dimension)\n",
    "\n",
    "# Add embeddings to a Faiss index.\n",
    "index.add(all_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. QUERY PIPELINE (RETRIEVAL + GENERATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query(user_query, top_k=3):\n",
    "    \"\"\"\n",
    "    1. Embed the user query (as text).\n",
    "    2. Retrieve top_k similar items from the PDF (text or image).\n",
    "    3. Build a ChatCompletion messages list with text + images.\n",
    "    4. Return GPT-4's answer.\n",
    "    \"\"\"\n",
    "    # Step 1: Embed user query\n",
    "    query_emb = embed_texts([user_query], clip_processor, clip_model)  # shape: (1, D)\n",
    "    \n",
    "    # Step 2: Retrieve from Faiss\n",
    "    distances, faiss_indices = search_index(index, query_emb, top_k=top_k)\n",
    "    retrieved_items = retrieve_context(faiss_indices, all_metadata)\n",
    "\n",
    "    # Step 3: Build the messages payload\n",
    "    # We'll pass the user's question as the first part of the content,\n",
    "    # then each retrieved item (text or image) as separate parts.\n",
    "    user_content = []\n",
    "    \n",
    "    # Add user query\n",
    "    user_content.append({\"type\": \"text\", \"text\": f\"User query: {user_query}\"})\n",
    "    \n",
    "    # Add each retrieved item\n",
    "    for item in retrieved_items:\n",
    "        if item[\"type\"] == \"text\":\n",
    "            # Provide textual snippet\n",
    "            user_content.append({\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"(page {item['page_number']}) {item['content'][:500]}...\"\n",
    "            })\n",
    "        elif item[\"type\"] == \"image\":\n",
    "            # Provide the base64 image data as a data URI\n",
    "            base64_str = item[\"content\"]\n",
    "            user_content.append({\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/png;base64,{base64_str}\"\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    # We'll provide one \"user\" message that contains a list of text + images\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant. Use both text and images to answer if relevant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_content  # <-- list of dicts (type: text or image_url)\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(json.dumps(messages, indent=2))  # Debug\n",
    "\n",
    "    # Step 4: Call GPT-4 with the full message payload\n",
    "    answer = call_gpt_4(messages)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. EXAMPLE USAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"You are a helpful assistant. Use both text and images to answer if relevant.\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": [\n",
      "      {\n",
      "        \"type\": \"text\",\n",
      "        \"text\": \"User query: What dogs like to do?\"\n",
      "      },\n",
      "      {\n",
      "        \"type\": \"text\",\n",
      "        \"text\": \"(page 1) The economic situation  \\n12 In the United States, GDP rose more than expected in the second quarter, by 0.7 per \\ncent compared with the first quarter of this year. Growth was partly due to a con -\\ntinued strong outcome in household consumption (see Figure 3). In July, too, house -\\nhold consumption remained strong, but the purchasing manager s\\u2019 index, for example, \\nsuggests weaker development going forward (see Figure 3).  \\nGrowth in China was marginally lower than expected during the second quar...\"\n",
      "      },\n",
      "      {\n",
      "        \"type\": \"text\",\n",
      "        \"text\": \"(page 4) The economic situation  \\n15 Figure 5.  Consumer prices in various countries and regions  \\nAnnual percentage change  \\n \\nNote. Refers to the CPIF for Sweden, the HICP for the euro area and the CPI for the United \\nStates.  \\nSources: Statistics Sweden, Eurostat and US Bureau of Labor Statistics.  \\nFigure 6.  Prices of goods and services abroad  \\nAnnual percentage ch ange  \\n \\nNote. Refers to the CPIF for Sweden, the HICP for the euro area and the CPI for the United \\nStates.  \\nSources: Eurostat , Stat...\"\n",
      "      },\n",
      "      {\n",
      "        \"type\": \"text\",\n",
      "        \"text\": \"(page 2) The economic situation  \\n13 Figure 3.  Purchasing managers\\u2019 index in the service sector and manufacturing sector  \\nIndex  \\n \\n  \\nNote. The purchasing managers\\u2019 index is an indicator of economic activity where an index \\nfigure above 50 indicates growth, while a figure below 50 indicates a downturn.  \\nSources: Institute for Supply Management, S&P Global and Swedbank.  \\nLabour market starting to weaken in United States  \\nIn the euro area, unemployment is still low and the employment rate is rising (...\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n",
      "\n",
      "Q: What dogs like to do?\n",
      "A: It seems like your query about what dogs like to do got mixed in with text regarding economic data. Letâ€™s address your original question about dogs.\n",
      "\n",
      "### What Dogs Like to Do\n",
      "\n",
      "Dogs are known for their playful and social nature. Here are some activities that many dogs enjoy:\n",
      "\n",
      "1. **Playing Fetch**: Many dogs love to chase after balls or frisbees. This activity is great for exercise and bonding with their owners.\n",
      "\n",
      "2. **Going for Walks**: Dogs generally enjoy exploring their surroundings. Regular walks are essential for their physical health and mental stimulation.\n",
      "\n",
      "3. **Socializing with Other Dogs**: Playdates at dog parks or in controlled environments allow dogs to interact and play with their peers.\n",
      "\n",
      "4. **Training and Learning Tricks**: Dogs enjoy mental challenges. Training sessions can be fun and rewarding, especially when treats are involved.\n",
      "\n",
      "5. **Swimming**: Many breeds, especially retrievers, love to swim and play in water.\n",
      "\n",
      "6. **Cuddling and Relaxing**: After a day of play, many dogs enjoy cuddling with their owners, showing affection and seeking comfort.\n",
      "\n",
      "7. **Exploring New Environments**: Dogs are naturally curious and enjoy new smells, sights, and experiences, whether it's a hike in the woods or a trip to a new park.\n",
      "\n",
      "8. **Chewing and Playing with Toys**: Dogs have a natural instinct to chew. Providing them with toys can satisfy this urge and keep them entertained.\n",
      "\n",
      "9. **Agility\n"
     ]
    }
   ],
   "source": [
    "user_query_1 = \"What dogs like to do?\"\n",
    "response_1 = answer_query(user_query_1, top_k=3)\n",
    "print(\"\\nQ:\", user_query_1)\n",
    "print(\"A:\", response_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
