{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation notebook\n",
    "\n",
    "### 1. Install / Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Skola\\Master's Thesis\\masters-thesis\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pdf2image import convert_from_path\n",
    "from common_utils import embed_texts, embed_images, encode_image_to_base64, search_index, retrieve_context, call_gpt_4, extract_figures_from_pdf\n",
    "from ragas import EvaluationDataset, evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "from ipynb.fs.full.classRag import RAG\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "load_dotenv()\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. EXTRACT IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file =\"../knowledge/subset_monetary_policy_report.pdf\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_images_from_pdf(pdf_path, output_folder=\"extracted_data\", padding=300, xpadding = 300):\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Create output folder\n",
    "    image_paths = []\n",
    "    \n",
    "    # Open the PDF document\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Loop through all pages in the PDF\n",
    "    for page_index in range(len(doc)):\n",
    "        page = doc.load_page(page_index)  # Load the page\n",
    "        \n",
    "        # Rasterize the page to an image\n",
    "        pix = page.get_pixmap(dpi=300)  # Convert to image with high DPI\n",
    "        full_image_path = os.path.join(output_folder, f\"full_page_{page_index + 1}.png\")\n",
    "        pix.save(full_image_path)\n",
    "        \n",
    "        # Convert the image to OpenCV format (numpy array)\n",
    "        full_image = cv2.imread(full_image_path)\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray_image = cv2.cvtColor(full_image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Threshold to create a binary image (to highlight potential image areas)\n",
    "        _, thresh = cv2.threshold(gray_image, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "        \n",
    "        # Find contours (regions that are \"boxes\" in the image)\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Loop through contours and crop the image regions\n",
    "        img_index = 0\n",
    "        for contour in contours:\n",
    "            # Get the bounding box of each contour (x, y, width, height)\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            \n",
    "            # Ignore small areas (you can adjust the threshold for min area size)\n",
    "            if w > 50 and h > 50:\n",
    "                # Add padding to the bounding box\n",
    "                x_padded = max(x - padding, 0)  # Ensure x doesn't go below 0\n",
    "                y_padded = max(y - padding, 0)  # Ensure y doesn't go below 0\n",
    "                w_padded = min(w + 2 * xpadding, full_image.shape[1] - x_padded)  # Ensure width doesn't exceed image\n",
    "                h_padded = min(h + 2 * padding, full_image.shape[0] - y_padded)  # Ensure height doesn't exceed image\n",
    "                \n",
    "                # Crop the image with padding\n",
    "                cropped_image = full_image[y_padded:y_padded + h_padded, x_padded:x_padded + w_padded]\n",
    "                \n",
    "                # Convert cropped image to PIL format to save it as PNG\n",
    "                pil_image = Image.fromarray(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))\n",
    "                img_filename = f\"page_{page_index + 1}_image_{img_index + 1}.png\"\n",
    "                img_path = os.path.join(output_folder, img_filename)\n",
    "                pil_image.save(img_path, \"PNG\")\n",
    "                \n",
    "                image_paths.append({\"image_path\": img_path})\n",
    "                img_index += 1\n",
    "    \n",
    "    doc.close()\n",
    "    return image_paths\n",
    "\n",
    "# image_paths = extract_images_from_pdf(file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. EXTRACT TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text_data = []\n",
    "    # Extract text\n",
    "    reader = PdfReader(file)\n",
    "    num_pages = len(reader.pages)\n",
    "\n",
    "    for page_i in range(num_pages):\n",
    "        page = reader.pages[page_i]\n",
    "        page_text = page.extract_text()\n",
    "        \n",
    "        if page_text and page_text.strip():\n",
    "            text_data.append({\n",
    "                \"text\": page_text.strip(),\n",
    "                \"page_number\": page_i + 1\n",
    "            })\n",
    "    return text_data\n",
    "\n",
    "#text_data = extract_text_from_pdf(file)\n",
    "#print(text_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_for_pdf(pdf_path):\n",
    "    output_json = \"QA_\" + os.path.basename(pdf_path).replace('.pdf', '.json')\n",
    "\n",
    "    # Extract images and text from PDF\n",
    "    image_data = extract_images_from_pdf(pdf_path)\n",
    "    text_data = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    sample_queries = []\n",
    "    expected_responses = []\n",
    "    qa_data = []\n",
    "\n",
    "    # Iterate over text data to generate questions\n",
    "    for text_info in text_data:\n",
    "        page_number = text_info[\"page_number\"]\n",
    "        page_text = text_info[\"text\"]\n",
    "\n",
    "        user_prompt = json.dumps([\n",
    "            {\"type\": \"text\", \"text\": (\n",
    "                \"Your task is to formulate a question from the given context while following these rules:\\n\"\n",
    "                \"1. The question must be answerable using the provided context.\\n\"\n",
    "                \"2. It should be based on non-trivial information.\\n\"\n",
    "                \"3. The answer must not contain any links.\\n\"\n",
    "                \"4. The question should be of moderate difficulty.\\n\"\n",
    "                \"5. Avoid phrases like 'provided context'.\\n\"\n",
    "                \"6. The response must be in valid JSON format as follows:\\n\"\n",
    "                \"{'question': 'Generated question here', 'answer': 'Generated answer here'}\"\n",
    "            )},\n",
    "            {\"type\": \"text\", \"text\": page_text}\n",
    "        ])\n",
    "        \n",
    "        response_text = call_gpt_4(user_prompt)\n",
    "        #print(f\"Raw API response for text (page {page_number}):\", response_text)\n",
    "\n",
    "        try:\n",
    "            cleaned_response_text = response_text.strip(\"```json\").strip(\"```\")  # Remove surrounding backticks\n",
    "            response_data = json.loads(cleaned_response_text)\n",
    "            question = response_data.get(\"question\")\n",
    "            answer = response_data.get(\"answer\")\n",
    "\n",
    "            if question and answer:\n",
    "                sample_queries.append(question)\n",
    "                expected_responses.append(answer)\n",
    "                qa_data.append({\"page_number\": page_number, \"question\": question, \"answer\": answer})\n",
    "            else:\n",
    "                print(f\"Warning: Missing Q&A data for text on page {page_number}\")\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON response for text on page {page_number}: {e}\")\n",
    "            print(\"Response text:\", response_text)\n",
    "            continue\n",
    "\n",
    "    # Iterate over image data to generate questions\n",
    "    for image_info in image_data:\n",
    "        page_number = image_info[\"image_path\"].split(\"_\")[2]  # Extract page number from image path\n",
    "        image_path = image_info[\"image_path\"]\n",
    "\n",
    "        # Convert the image to base64 for processing\n",
    "        image = Image.open(image_path)\n",
    "        base64_str = encode_image_to_base64(image)\n",
    "\n",
    "        user_prompt = json.dumps([\n",
    "            {\"type\": \"text\", \"text\": (\n",
    "                \"Your task is to formulate a question from the given image while following these rules:\\n\"\n",
    "                \"1. The question must be answerable using the provided image.\\n\"\n",
    "                \"2. It should be based on non-trivial information.\\n\"\n",
    "                \"3. The answer must not contain any links.\\n\"\n",
    "                \"4. The question should be of moderate difficulty.\\n\"\n",
    "                \"5. Avoid phrases like 'provided image'.\\n\"\n",
    "                \"6. The response must be in valid JSON format as follows:\\n\"\n",
    "                \"{'question': 'Generated question here', 'answer': 'Generated answer here'}\"\n",
    "            )},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_str}\"}}\n",
    "        ])\n",
    "\n",
    "        response_text = call_gpt_4(user_prompt)\n",
    "        #print(f\"Raw API response for image (page {page_number}):\", response_text)\n",
    "\n",
    "        try:\n",
    "            cleaned_response_text = response_text.strip(\"```json\").strip(\"```\")  # Remove surrounding backticks\n",
    "            response_data = json.loads(cleaned_response_text)\n",
    "            question = response_data.get(\"question\")\n",
    "            answer = response_data.get(\"answer\")\n",
    "\n",
    "            if question and answer:\n",
    "                sample_queries.append(question)\n",
    "                expected_responses.append(answer)\n",
    "                qa_data.append({\"page_number\": page_number, \"question\": question, \"answer\": answer})\n",
    "            else:\n",
    "                print(f\"Warning: Missing Q&A data for image on page {page_number}\")\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON response for image on page {page_number}: {e}\")\n",
    "            print(\"Response text:\", response_text)\n",
    "            continue\n",
    "\n",
    "    # Output structured data\n",
    "    output = {\n",
    "        \"sample_queries\": sample_queries,\n",
    "        \"expected_responses\": expected_responses,\n",
    "        \"qa_data\": qa_data\n",
    "    }\n",
    "\n",
    "    with open(output_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    #print(\"Final Q&A data saved to\", output_json)\n",
    "    return sample_queries, expected_responses, qa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What was the total amount of interest-bearing debt for Swedish non-financial companies at the end of 2023, and how was this debt distributed between loans and issued debt securities?', 'What are the main sources of borrowing for large enterprises and SMEs in Sweden as of December 31, 2023, and how does this differ by enterprise size?', 'Which sectors have the highest share of securities borrowing, and what are the primary sources of loans for non-financial companies in Sweden?', 'What were some of the reasons for the increased demand for debt securities issued by Swedish companies after the financial crisis?', \"What was the market value of companies' outstanding equities in Sweden at the end of 2023, and how does it compare to the country's GDP?\", \"What is the significance of the 'q2' symbol in the provided image?\", 'What is the primary color scheme used in the image and how does it affect the overall vibe?', 'What is the unique feature of the design on the object shown in the image?', 'What is the main theme or concept emphasized in this image?', 'What is the main purpose of the JSON format provided in the given task?', \"What is the significance of the image showing 'Your task is to formulate a question from the given image while following these rules'?\"]\n",
      "['At the end of 2023, the total amount of interest-bearing debt for Swedish non-financial companies was just over SEK 5,500 billion. This debt was distributed as SEK 4,000 billion in loans from banks and other lenders, and SEK 1,500 billion in issued debt securities.', 'As of December 31, 2023, large enterprises in Sweden, whether publicly or not publicly owned, primarily borrow from banks and other monetary financial institutions (MFIs), as well as through debt securities. Small and medium-sized enterprises (SMEs), including micro-enterprises, mainly rely on loans from banks and other MFIs. The borrowing methods differ by the size of the enterprise, as larger companies have more access to diverse financing options, such as debt securities, compared to SMEs.', 'The sectors with the highest share of securities borrowing are companies active in energy and water supply, certain industrial and property operations, and certain service industries. For non-financial companies in Sweden, the primary sources of loans are financial corporations, mainly banks, which account for more than 70 percent of the loan volume. Other financial companies, municipalities, regions, and foreign lenders also contribute to some extent.', 'The increased demand for debt securities issued by Swedish companies after the financial crisis can be attributed to low interest rates, which lowered absolute returns and increased investor demand for riskier assets. Additionally, the price of securities financing became more favorable compared to bank loans.', \"At the end of 2023, the market value of companies' outstanding equities in Sweden amounted to just over SEK 21,000 billion, which is equivalent to around 340 percent of the country's GDP.\", \"The 'q2' symbol in the image likely represents a specific point or location on a map or diagram that requires further analysis or action, as it is often used in technical or scientific contexts to denote a particular area of interest.\", 'The primary color scheme used in the image is a combination of earthy tones like greens and browns. This color scheme gives the image a natural and calming vibe.', 'The unique feature of the design on the object is its intricate and symmetrical pattern, which resembles a maze or labyrinth with multiple layers and paths.', 'The main theme of the image revolves around the technological advancement and connectivity facilitated by modern communication networks, as depicted by the intricate web of nodes and lines representing a digital network or the internet.', 'The main purpose of the JSON format provided in the task is to structure the generated question and answer in a standardized way, allowing for easy parsing and understanding of the response.', 'The image provides instructions to create a question based on the image, following specific rules to ensure the question is answerable, contains non-trivial information, and avoids certain phrases and formats.']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    PDF_FILE = \"../knowledge/subset_monetary_policy_report.pdf\"\n",
    "    sample_queries, expected_responses, qa_data = generate_qa_for_pdf(pdf_path=PDF_FILE)\n",
    "    print(sample_queries)\n",
    "    print(expected_responses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34d35bb7a41995741358303864c0abd463933b7f4684d12ed372b9f8e1810ab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
